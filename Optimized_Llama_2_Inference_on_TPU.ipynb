{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayagup/stablediffusion/blob/main/Optimized_Llama_2_Inference_on_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install \"optimum-tpu>=0.1.0\" \"transformers>=4.40.0\" \"accelerate\" \"datasets\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DBKQjlofub8",
        "outputId": "e49d8955-4356-43e5-e144-c54fdc1b4b7f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optimum-tpu>=0.1.0\n",
            "  Using cached optimum_tpu-0.2.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting transformers>=4.40.0\n",
            "  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting datasets\n",
            "  Using cached datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting transformers>=4.40.0\n",
            "  Using cached transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting torch==2.5.1 (from optimum-tpu>=0.1.0)\n",
            "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torch-xla==2.5.1 (from torch-xla[tpu]==2.5.1->optimum-tpu>=0.1.0)\n",
            "  Downloading torch_xla-2.5.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
            "Collecting typer==0.6.1 (from optimum-tpu>=0.1.0)\n",
            "  Downloading typer-0.6.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting loguru==0.6.0 (from optimum-tpu>=0.1.0)\n",
            "  Downloading loguru-0.6.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting sentencepiece==0.2.0 (from optimum-tpu>=0.1.0)\n",
            "  Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers>=4.40.0) (3.19.1)\n",
            "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers>=4.40.0)\n",
            "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy>=1.17 (from transformers>=4.40.0)\n",
            "  Downloading numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Collecting packaging>=20.0 (from transformers>=4.40.0)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.40.0) (6.0.2)\n",
            "Collecting regex!=2019.12.17 (from transformers>=4.40.0)\n",
            "  Downloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.40.0) (2.32.5)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers>=4.40.0)\n",
            "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers>=4.40.0)\n",
            "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting tqdm>=4.27 (from transformers>=4.40.0)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->optimum-tpu>=0.1.0) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->optimum-tpu>=0.1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->optimum-tpu>=0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->optimum-tpu>=0.1.0) (2025.7.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1->optimum-tpu>=0.1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1->optimum-tpu>=0.1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1->optimum-tpu>=0.1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1->optimum-tpu>=0.1.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1->optimum-tpu>=0.1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1->optimum-tpu>=0.1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1->optimum-tpu>=0.1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1->optimum-tpu>=0.1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1->optimum-tpu>=0.1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1->optimum-tpu>=0.1.0)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.1->optimum-tpu>=0.1.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1->optimum-tpu>=0.1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch==2.5.1->optimum-tpu>=0.1.0)\n",
            "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting sympy==1.13.1 (from torch==2.5.1->optimum-tpu>=0.1.0)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1->optimum-tpu>=0.1.0) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from torch-xla==2.5.1->torch-xla[tpu]==2.5.1->optimum-tpu>=0.1.0) (2.3.1)\n",
            "INFO: pip is looking at multiple versions of torch-xla[tpu] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting optimum-tpu>=0.1.0\n",
            "  Using cached optimum_tpu-0.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "  Using cached optimum_tpu-0.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting transformers>=4.40.0\n",
            "  Using cached transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n",
            "Collecting torch==2.4.0 (from optimum-tpu>=0.1.0)\n",
            "  Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torch-xla==2.4.0 (from torch-xla[tpu]==2.4.0->optimum-tpu>=0.1.0)\n",
            "  Downloading torch_xla-2.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: cloud-tpu-client>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from torch-xla[tpu]==2.4.0->optimum-tpu>=0.1.0) (0.10)\n",
            "Collecting optimum-tpu>=0.1.0\n",
            "  Using cached optimum_tpu-0.1.5-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: torch<=2.4.0,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from optimum-tpu>=0.1.0) (2.3.0)\n",
            "Requirement already satisfied: torch-xla<=2.4.0,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch-xla[tpu]<=2.4.0,>=2.3.0->optimum-tpu>=0.1.0) (2.3.0)\n",
            "Requirement already satisfied: libtpu-nightly==0.1.dev20240322 in /usr/local/lib/python3.11/dist-packages (from torch-xla[tpu]<=2.4.0,>=2.3.0->optimum-tpu>=0.1.0) (0.1.dev20240322+default)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers>=4.40.0)\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.23.2->transformers>=4.40.0)\n",
            "  Downloading hf_xet-1.1.8-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (703 bytes)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0,>=2.3.0->optimum-tpu>=0.1.0) (1.14.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0,>=2.3.0->optimum-tpu>=0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0,>=2.3.0->optimum-tpu>=0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0,>=2.3.0->optimum-tpu>=0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0,>=2.3.0->optimum-tpu>=0.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0,>=2.3.0->optimum-tpu>=0.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0,>=2.3.0->optimum-tpu>=0.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0,>=2.3.0->optimum-tpu>=0.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0,>=2.3.0->optimum-tpu>=0.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0,>=2.3.0->optimum-tpu>=0.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0,>=2.3.0->optimum-tpu>=0.1.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0,>=2.3.0->optimum-tpu>=0.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0,>=2.3.0->optimum-tpu>=0.1.0) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<=2.4.0,>=2.3.0->optimum-tpu>=0.1.0) (12.9.86)\n",
            "Collecting psutil (from accelerate)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pandas (from datasets)\n",
            "  Downloading pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers>=4.40.0)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from cloud-tpu-client>=0.10.0->torch-xla[tpu]==2.4.0->optimum-tpu>=0.1.0) (1.8.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.11/dist-packages (from cloud-tpu-client>=0.10.0->torch-xla[tpu]==2.4.0->optimum-tpu>=0.1.0) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/lib/python3/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla[tpu]==2.4.0->optimum-tpu>=0.1.0) (0.20.2)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla[tpu]==2.4.0->optimum-tpu>=0.1.0) (2.40.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla[tpu]==2.4.0->optimum-tpu>=0.1.0) (0.2.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla[tpu]==2.4.0->optimum-tpu>=0.1.0) (1.34.1)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/lib/python3/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla[tpu]==2.4.0->optimum-tpu>=0.1.0) (1.16.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla[tpu]==2.4.0->optimum-tpu>=0.1.0) (3.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla[tpu]==2.4.0->optimum-tpu>=0.1.0) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla[tpu]==2.4.0->optimum-tpu>=0.1.0) (3.20.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla[tpu]==2.4.0->optimum-tpu>=0.1.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla[tpu]==2.4.0->optimum-tpu>=0.1.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla[tpu]==2.4.0->optimum-tpu>=0.1.0) (4.9.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/lib/python3/dist-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla[tpu]==2.4.0->optimum-tpu>=0.1.0) (2.4.7)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.40.0) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.40.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.40.0) (2025.8.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from rsa<5,>=3.1.4->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla[tpu]==2.4.0->optimum-tpu>=0.1.0) (0.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch==2.5.1->optimum-tpu>=0.1.0) (2.0.1)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->datasets)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading optimum_tpu-0.1.5-py3-none-any.whl (77 kB)\n",
            "Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.1.8-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.10.0-py3-none-any.whl (374 kB)\n",
            "Downloading numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m154.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
            "Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\n",
            "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
            "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.9/798.9 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m146.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Installing collected packages: sentencepiece, pytz, xxhash, tzdata, tqdm, safetensors, regex, python-dateutil, pyarrow, psutil, propcache, packaging, numpy, multidict, loguru, hf-xet, fsspec, frozenlist, dill, attrs, aiohappyeyeballs, yarl, pandas, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, accelerate, datasets, optimum-tpu\n",
            "\u001b[2K  Attempting uninstall: fsspec\n",
            "\u001b[2K    Found existing installation: fsspec 2025.7.0\n",
            "\u001b[2K    Uninstalling fsspec-2025.7.0:\n",
            "\u001b[2K      Successfully uninstalled fsspec-2025.7.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32/32\u001b[0m [optimum-tpu]\n",
            "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.10.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 attrs-25.3.0 datasets-4.0.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 hf-xet-1.1.8 huggingface-hub-0.34.4 loguru-0.6.0 multidict-6.6.4 multiprocess-0.70.16 numpy-2.3.2 optimum-tpu-0.1.5 packaging-25.0 pandas-2.3.2 propcache-0.3.2 psutil-7.0.0 pyarrow-21.0.0 python-dateutil-2.9.0.post0 pytz-2025.2 regex-2025.7.34 safetensors-0.6.2 sentencepiece-0.2.0 tokenizers-0.19.1 tqdm-4.67.1 transformers-4.41.1 tzdata-2025.2 xxhash-3.5.0 yarl-1.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -sS https://bootstrap.pypa.io/get-pip.py -o get-pip.py"
      ],
      "metadata": {
        "id": "rmniBqbe3QGb"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.11 get-pip.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVdRygMX6hJb",
        "outputId": "4bab3106-935c-4204-eaaf-5168c4c9f9ba"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting wheel\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pip]\n",
            "\u001b[1A\u001b[2KSuccessfully installed pip-25.2 setuptools-80.9.0 wheel-0.45.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update && apt-get install python3.11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UZKzn8N6kra",
        "outputId": "71aafc9d-18de-489f-88a6-fbc2a061744e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pip 25.2 from /usr/local/lib/python3.11/dist-packages/pip (python 3.11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.3.0 'torch_xla[tpu]==2.3.0' -f https://storage.googleapis.com/libtpu-releases/index.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWQ6i_fc0N5d",
        "outputId": "2c2e23d1-8196-45d3-fb42-bdc118aae97f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/libtpu-releases/index.html\n",
            "Collecting torch==2.3.0\n",
            "  Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torch_xla==2.3.0 (from torch_xla[tpu]==2.3.0)\n",
            "  Downloading torch_xla-2.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (7.9 kB)\n",
            "Collecting filelock (from torch==2.3.0)\n",
            "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch==2.3.0)\n",
            "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch==2.3.0)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch==2.3.0)\n",
            "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.3.0)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.3.0)\n",
            "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.0 (from torch==2.3.0)\n",
            "  Downloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting absl-py>=1.0.0 (from torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting cloud-tpu-client>=0.10.0 (from torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading cloud_tpu_client-0.10-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting pyyaml (from torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting libtpu-nightly==0.1.dev20240322 (from torch_xla[tpu]==2.3.0)\n",
            "  Downloading https://storage.googleapis.com/libtpu-nightly-releases/wheels/libtpu-nightly/libtpu_nightly-0.1.dev20240322%2Bdefault-py3-none-any.whl (115.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.0/115.0 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting google-api-python-client==1.8.0 (from cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading google_api_python_client-1.8.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting oauth2client (from cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/lib/python3/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0) (0.20.2)\n",
            "Collecting google-auth>=1.4.1 (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting google-auth-httplib2>=0.0.3 (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting google-api-core<2dev,>=1.13.0 (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading google_api_core-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/lib/python3/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0) (1.16.0)\n",
            "Collecting uritemplate<4dev,>=3.0.0 (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting googleapis-common-protos<2.0dev,>=1.56.2 (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Collecting requests<3.0.0dev,>=2.18.0 (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/lib/python3/dist-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0) (2.4.7)\n",
            "Collecting charset_normalizer<4,>=2 (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch_xla==2.3.0->torch_xla[tpu]==2.3.0)\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch==2.3.0) (2.0.1)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.3.0)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl (779.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0m\n",
            "\u001b[?25hDownloading torch_xla-2.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (84.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.3/84.3 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m151.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m159.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m?\u001b[0m  \u001b[33m0:00:34\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
            "Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n",
            "Downloading google_api_python_client-1.8.0-py3-none-any.whl (57 kB)\n",
            "Downloading google_api_core-1.34.1-py3-none-any.whl (120 kB)\n",
            "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
            "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
            "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (150 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
            "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
            "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
            "Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, libtpu-nightly, urllib3, uritemplate, typing-extensions, sympy, pyyaml, pyasn1, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, jinja2, idna, fsspec, filelock, charset_normalizer, certifi, cachetools, absl-py, triton, rsa, requests, pyasn1-modules, nvidia-cusparse-cu12, nvidia-cudnn-cu12, googleapis-common-protos, oauth2client, nvidia-cusolver-cu12, google-auth, torch, google-auth-httplib2, google-api-core, google-api-python-client, cloud-tpu-client, torch_xla\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43/43\u001b[0m [torch_xla]\n",
            "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 cachetools-5.5.2 certifi-2025.8.3 charset_normalizer-3.4.3 cloud-tpu-client-0.10 filelock-3.19.1 fsspec-2025.7.0 google-api-core-1.34.1 google-api-python-client-1.8.0 google-auth-2.40.3 google-auth-httplib2-0.2.0 googleapis-common-protos-1.70.0 idna-3.10 jinja2-3.1.6 libtpu-nightly-0.1.dev20240322+default mpmath-1.3.0 networkx-3.5 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 oauth2client-4.1.3 protobuf-3.20.3 pyasn1-0.6.1 pyasn1-modules-0.4.2 pyyaml-6.0.2 requests-2.32.5 rsa-4.9.1 sympy-1.14.0 torch-2.3.0 torch_xla-2.3.0 triton-2.3.0 typing-extensions-4.14.1 uritemplate-3.0.1 urllib3-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# A complete guide for running a Llama-2 model on a Google Cloud TPU using optimum-tpu and PyTorch/XLA.\n",
        "#\n",
        "# This script is designed to be executed in a properly configured Google Cloud TPU VM.\n",
        "# It uses torch_xla.distributed.xla_multiprocessing to launch a separate process on each\n",
        "# of the 8 TPU cores, which is the most efficient way to utilize the hardware.\n",
        "#\n",
        "# Prerequisites (run this in your shell on the TPU VM):\n",
        "# 1. Install necessary libraries, including the TPU-specific PyTorch/XLA wheels:\n",
        "#    pip install optimum-tpu -f https://storage.googleapis.com/libtpu-releases/index.html\n",
        "#    pip install transformers accelerate datasets torch\n",
        "#\n",
        "# 2. Log in to the Hugging Face Hub if the model is gated (like Llama 2):\n",
        "#    from huggingface_hub import login\n",
        "#    login(token=\"YOUR_HUGGINGFACE_TOKEN\")\n",
        "#\n",
        "#    Note: This token should be a secure environment variable in a real-world scenario.\n",
        "#\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from accelerate import Accelerator\n"
      ],
      "metadata": {
        "id": "6jlpmSXlfxcz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0893b81b-1157-459c-ad6a-434cfdfd0a61"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_xla/experimental/gru.py:113: SyntaxWarning: invalid escape sequence '\\_'\n",
            "  * **h_n**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{out})` or\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Log in to the Hugging Face Hub if the model is gated (like Llama 2).\n",
        "# The user needs to manually create a token and paste it here or use\n",
        "# a secret store. Replace \"YOUR_HUGGINGFACE_TOKEN\" with your actual token.\n",
        "from huggingface_hub import login\n",
        "login(token=\"YOUR_HUGGINGFACE_TOKEN\")"
      ],
      "metadata": {
        "id": "D-KuLKr1gKbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The PJRT_DEVICE environment variable must be set to 'TPU' for PyTorch/XLA to\n",
        "# use the TPU device. This is often set automatically in a TPU VM environment.\n",
        "os.environ['PJRT_DEVICE'] = 'TPU'\n",
        "\n",
        "\n",
        "def run_tpu_inference(index, args):\n",
        "    \"\"\"\n",
        "    This function runs on each of the TPU cores. The 'index' corresponds\n",
        "    to the ID of the core (0-7 for an 8-core TPU).\n",
        "\n",
        "    Args:\n",
        "        index (int): The index of the current TPU core process.\n",
        "        args (tuple): A tuple containing any additional arguments passed to the function.\n",
        "    \"\"\"\n",
        "    # Get the TPU device for the current process\n",
        "    device = xm.xla_device()\n",
        "    print(f\"Process {index}: Initializing on device {device}\")\n",
        "\n",
        "    # Model ID for Llama-2. We'll use the 7B model as a common example.\n",
        "    # The principles apply directly to the 3B model as well.\n",
        "    model_id = \"meta-llama/Llama-2-7b-hf\"\n",
        "\n",
        "    try:\n",
        "        # Load the tokenizer\n",
        "        if xm.is_master_ordinal():\n",
        "            print(\"Loading tokenizer...\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "        # Load the model with `torch.bfloat16` for optimal performance on TPUs.\n",
        "        # `device_map=\"auto\"` uses accelerate to automatically handle sharding and\n",
        "        # placement of the model across all available devices (TPU cores).\n",
        "        if xm.is_master_ordinal():\n",
        "            print(\"Loading model...\")\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.bfloat16,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "\n",
        "        # A simple test prompt.\n",
        "        prompt = \"Explain the importance of TPU for large language models.\"\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # Ensure all processes have loaded the model before proceeding.\n",
        "        # This is crucial for distributed training/inference.\n",
        "        xm.mark_step()\n",
        "\n",
        "        # Only the master process needs to print the generation message.\n",
        "        if xm.is_master_ordinal():\n",
        "            print(\"Generating text...\")\n",
        "\n",
        "        # Generate a response.\n",
        "        # The first run will trigger JIT compilation by PyTorch/XLA, which can take\n",
        "        # some time but optimizes subsequent runs.\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=100,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            num_return_sequences=1\n",
        "        )\n",
        "\n",
        "        # Only the master process decodes and prints the result.\n",
        "        if xm.is_master_ordinal():\n",
        "            decoded_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"Generated Text:\")\n",
        "            print(decoded_text)\n",
        "            print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred on process {index}: {e}\")\n",
        "        # Print TPU metrics for debugging in case of an error on any process.\n",
        "        print(f\"TPU Metrics (Process {index}):\")\n",
        "        print(met.metrics_report())\n"
      ],
      "metadata": {
        "id": "d4UIAPP-fXhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Use xla_multiprocessing to spawn processes, one for each TPU core.\n",
        "    # The number of cores is automatically detected by the system.\n",
        "    num_tpu_cores = xm.xrt_world_size()\n",
        "    print(f\"Detected {num_tpu_cores} TPU cores. Spawning a process for each.\")\n",
        "\n",
        "    # The xmp.spawn call sets up the distributed environment and launches\n",
        "    # the 'run_tpu_inference' function on each core.\n",
        "    xmp.spawn(run_tpu_inference, args=({}), nprocs=num_tpu_cores, start_method='fork')"
      ],
      "metadata": {
        "id": "VrM5g3s5farK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}