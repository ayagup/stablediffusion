{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "depth_estimation.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayagup/stablediffusion/blob/main/depth_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "KcEkoX-hlMSs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install torch>=2.0.0 transformers>=4.35.0 accelerate>=0.24.0 Pillow>=10.0.0 opencv-python>=4.8.0 matplotlib>=3.7.0 numpy<2.0.0 timm>=0.9.0\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-18T18:20:04.676035Z",
          "iopub.execute_input": "2025-10-18T18:20:04.676252Z",
          "iopub.status.idle": "2025-10-18T18:20:04.806486Z",
          "shell.execute_reply.started": "2025-10-18T18:20:04.67623Z",
          "shell.execute_reply": "2025-10-18T18:20:04.805688Z"
        },
        "id": "9fJ23lislMSu",
        "outputId": "5fe3fb10-bf6b-40e0-b742-85b254248516"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/bin/bash: line 1: 2.0.0: No such file or directory\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install torch transformers accelerate Pillow opencv-python matplotlib \"numpy<2.0.0\" timm"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-18T18:22:18.847715Z",
          "iopub.execute_input": "2025-10-18T18:22:18.848517Z",
          "iopub.status.idle": "2025-10-18T18:22:32.655803Z",
          "shell.execute_reply.started": "2025-10-18T18:22:18.848486Z",
          "shell.execute_reply": "2025-10-18T18:22:32.654825Z"
        },
        "id": "T3FpK_I9lMSu",
        "outputId": "31b838ec-ff0b-45ac-e6ec-9734148f0c40"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.19)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.19.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.9.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nCollecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.1.0)\nINFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\nCollecting opencv-python\n  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0) (2.4.1)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.10)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0.0) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0.0) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m \u001b[32m650.1/664.8 MB\u001b[0m \u001b[31m198.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m^C:01\u001b[0m\n\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m \u001b[32m650.1/664.8 MB\u001b[0m \u001b[31m198.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Simple Depth Estimation Example\n",
        "Quick test for monocular depth estimation using Hugging Face models\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from transformers import AutoImageProcessor, AutoModelForDepthEstimation\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "\n",
        "# Suppress warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "# Memory optimization\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "\n",
        "def simple_depth_estimation(\n",
        "    image_path: str,\n",
        "    output_path: str = \"depth_map.png\",\n",
        "    model_name: str = \"Intel/dpt-large\",\n",
        "    colormap: str = \"viridis\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Estimate depth from a single image\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to input image (local file or URL)\n",
        "        output_path: Path to save depth map\n",
        "        model_name: HuggingFace model name\n",
        "        colormap: Matplotlib colormap for visualization\n",
        "    \"\"\"\n",
        "\n",
        "    # Clear GPU memory from any previous runs\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        print(\"üßπ Cleared GPU memory cache\\n\")\n",
        "\n",
        "    # Check GPU\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    num_gpus = torch.cuda.device_count() if device == \"cuda\" else 0\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Simple Depth Estimation\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Device: {device}\")\n",
        "    if num_gpus > 0:\n",
        "        print(f\"GPUs: {num_gpus}\")\n",
        "        for i in range(num_gpus):\n",
        "            print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Load image\n",
        "    print(f\"Loading image: {image_path}\")\n",
        "    if image_path.startswith('http://') or image_path.startswith('https://'):\n",
        "        # Load from URL\n",
        "        import requests\n",
        "        from io import BytesIO\n",
        "        response = requests.get(image_path)\n",
        "        image = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "    else:\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "    print(f\"Image size: {image.size[0]}x{image.size[1]}\")\n",
        "\n",
        "    # Load model and processor\n",
        "    print(f\"\\nLoading model: {model_name}\")\n",
        "    print(\"(This will download the model on first run)\\n\")\n",
        "\n",
        "    processor = AutoImageProcessor.from_pretrained(model_name)\n",
        "    model = AutoModelForDepthEstimation.from_pretrained(model_name)\n",
        "\n",
        "    # Move to GPU with memory optimization\n",
        "    if device == \"cuda\":\n",
        "        if num_gpus > 1:\n",
        "            print(f\"üöÄ Multi-GPU mode: distributing across {num_gpus} GPUs\")\n",
        "            # Use DataParallel for multi-GPU\n",
        "            model = torch.nn.DataParallel(model)\n",
        "            model = model.to(device)\n",
        "        else:\n",
        "            print(f\"‚ö° Single GPU mode\")\n",
        "            model = model.to(device)\n",
        "    else:\n",
        "        model = model.to(device)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    print(\"\\nEstimating depth...\")\n",
        "\n",
        "    # Prepare inputs\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predicted_depth = outputs.predicted_depth\n",
        "\n",
        "    # Post-process\n",
        "    prediction = predicted_depth.squeeze().cpu().numpy()\n",
        "\n",
        "    # Normalize to 0-255\n",
        "    depth_min = prediction.min()\n",
        "    depth_max = prediction.max()\n",
        "    normalized_depth = (prediction - depth_min) / (depth_max - depth_min)\n",
        "    normalized_depth = (normalized_depth * 255).astype(np.uint8)\n",
        "\n",
        "    print(f\"Depth range: {depth_min:.2f} to {depth_max:.2f}\")\n",
        "\n",
        "    # Apply colormap\n",
        "    import matplotlib.pyplot as plt\n",
        "    import matplotlib.cm as cm\n",
        "\n",
        "    cmap = cm.get_cmap(colormap)\n",
        "    colored_depth = cmap(normalized_depth / 255.0)\n",
        "    colored_depth = (colored_depth[:, :, :3] * 255).astype(np.uint8)\n",
        "\n",
        "    # Save\n",
        "    depth_image = Image.fromarray(colored_depth)\n",
        "\n",
        "    # Resize to match input image size\n",
        "    depth_image = depth_image.resize(image.size, Image.LANCZOS)\n",
        "    depth_image.save(output_path)\n",
        "\n",
        "    print(f\"\\n‚úÖ Success!\")\n",
        "    print(f\"Depth map saved to: {output_path}\")\n",
        "    print(f\"Output size: {depth_image.size[0]}x{depth_image.size[1]}\\n\")\n",
        "\n",
        "    return normalized_depth, depth_image\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-18T18:27:15.095982Z",
          "iopub.execute_input": "2025-10-18T18:27:15.096295Z",
          "iopub.status.idle": "2025-10-18T18:27:15.108457Z",
          "shell.execute_reply.started": "2025-10-18T18:27:15.096274Z",
          "shell.execute_reply": "2025-10-18T18:27:15.107691Z"
        },
        "id": "hU-UzEa4lMSv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# if __name__ == \"__main__\":\n",
        "#     import argparse\n",
        "\n",
        "#     parser = argparse.ArgumentParser(description='Simple Depth Estimation')\n",
        "#     parser.add_argument('--image', type=str, required=True,\n",
        "#                         help='Path to input image')\n",
        "#     parser.add_argument('--output', type=str, default='depth_map.png',\n",
        "#                         help='Output depth map path')\n",
        "#     parser.add_argument('--model', type=str, default='Intel/dpt-large',\n",
        "#                         help='Model name (Intel/dpt-large, Intel/dpt-hybrid-midas, etc.)')\n",
        "#     parser.add_argument('--colormap', type=str, default='viridis',\n",
        "#                         help='Matplotlib colormap (viridis, plasma, inferno, magma)')\n",
        "\n",
        "#     args = parser.parse_args()\n",
        "\n",
        "try:\n",
        "    simple_depth_estimation(\n",
        "        image_path='https://cdn.getyourguide.com/image/format=auto,fit=contain,gravity=auto,quality=60,width=1440,height=650,dpr=2/tour_img/cbd0dea59e2a7432c2e279cc6af7fd14b8c67f31353c27c5f157ea07dc458b71.png',\n",
        "        output_path='/kaggle/working/depth_map.png',\n",
        "        model_name='Intel/dpt-large',\n",
        "        colormap='viridis',\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-18T18:27:15.874742Z",
          "iopub.execute_input": "2025-10-18T18:27:15.875452Z",
          "iopub.status.idle": "2025-10-18T18:27:27.255468Z",
          "shell.execute_reply.started": "2025-10-18T18:27:15.875428Z",
          "shell.execute_reply": "2025-10-18T18:27:27.254599Z"
        },
        "id": "ezNzXrPDlMSw",
        "outputId": "61212ae5-b4af-4ce9-f62d-641ca54b1578",
        "colab": {
          "referenced_widgets": [
            "f258e87ae4d649a1a59983aa916f9ced",
            "fdf582b33b284e0aab7afa7e06223592",
            "326d0abc68884dc9885fa6418a5198bd"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "üßπ Cleared GPU memory cache\n\n\n============================================================\nSimple Depth Estimation\n============================================================\nDevice: cuda\nGPUs: 1\n  GPU 0: Tesla P100-PCIE-16GB\n============================================================\n\nLoading image: https://cdn.getyourguide.com/image/format=auto,fit=contain,gravity=auto,quality=60,width=1440,height=650,dpr=2/tour_img/cbd0dea59e2a7432c2e279cc6af7fd14b8c67f31353c27c5f157ea07dc458b71.png\nImage size: 1947x1300\n\nLoading model: Intel/dpt-large\n(This will download the model on first run)\n\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "preprocessor_config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f258e87ae4d649a1a59983aa916f9ced"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/942 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdf582b33b284e0aab7afa7e06223592"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/1.37G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "326d0abc68884dc9885fa6418a5198bd"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of DPTForDepthEstimation were not initialized from the model checkpoint at Intel/dpt-large and are newly initialized: ['neck.fusion_stage.layers.0.residual_layer1.convolution1.bias', 'neck.fusion_stage.layers.0.residual_layer1.convolution1.weight', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.bias', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "‚ö° Single GPU mode\n\nEstimating depth...\nDepth range: 0.00 to 38.92\n\n‚úÖ Success!\nDepth map saved to: /kaggle/working/depth_map.png\nOutput size: 1947x1300\n\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_37/155392916.py:117: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  cmap = cm.get_cmap(colormap)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "NvQEyyzJlMSw"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}